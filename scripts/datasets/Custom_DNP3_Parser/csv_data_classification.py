# -*- coding: utf-8 -*-
"""csv_data_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PcgCpr_XVRKkeGB3mvIFQ9ok9mXyqkVz
"""

import pandas as pd
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Input
from tensorflow.keras.utils import to_categorical
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import f1_score
from sklearn.metrics import recall_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import MinMaxScaler

train_file = input('Training File : ') 
test_file = input("Testing File : ")
noc = int(input("No of Classes : "))  # no of classes in your output

data = pd.read_csv(train_file)
data = data.replace([np.inf, -np.inf], np.nan).dropna(axis=0)

output = data.iloc[:, -1]
input_data = data.iloc[:, :-1]
string_columns = input_data.select_dtypes(include=['object'])
input_data = input_data.drop(string_columns, axis=1)

correlation_matrix = input_data.corr()
correlation_threshold = 0.95
mask = (correlation_matrix.abs() >= correlation_threshold) & (correlation_matrix.abs() < 1.0)
features_to_remove = set()

for feature in correlation_matrix.columns:
    if feature not in features_to_remove:
        correlated_features = list(correlation_matrix.index[mask[feature]])
        if feature in correlated_features :
          correlated_features.remove(feature)
        features_to_remove.update(correlated_features)

features_to_remove = list(features_to_remove)

input_data_filtered = input_data.drop(columns=features_to_remove)

scaler = MinMaxScaler()
input_data_normalized = scaler.fit_transform(input_data_filtered)
input_data_normalized_df = pd.DataFrame(input_data_normalized, columns=input_data_filtered.columns)

label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(output)

y_train = to_categorical(y_encoded, num_classes=noc)

model = Sequential()
model.add(Input(shape = (input_data_normalized_df.shape[1],)))
for i in range(1,11) :
  model.add(Dense(90, activation='relu'))
model.add(Dense(noc, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

model.fit(input_data_normalized_df, y_train , epochs=100, batch_size=16,verbose=0)

"""**Testing**"""

data_test = pd.read_csv(test_file)
data_test = data_test.replace([np.inf, -np.inf], np.nan).dropna(axis=0)

output_test = data_test.iloc[:, -1]
input_test = data_test.iloc[:, :-1]
string_columns_test = input_test.select_dtypes(include=['object'])
input_test = input_test.drop(string_columns_test, axis=1)
input_data_filtered_test = input_test.drop(columns=features_to_remove)

scaler = MinMaxScaler()
input_data_normalized_test = scaler.fit_transform(input_data_filtered_test)
input_data_normalized_df_test = pd.DataFrame(input_data_normalized_test, columns=input_data_filtered_test.columns)

label_encoder = LabelEncoder()
y_encoded_test = label_encoder.fit_transform(output_test)
# y_test = to_categorical(y_encoded_test, num_classes=noc)

y_pred_encoded = model.predict(input_data_normalized_df_test)
y_pred_labels = [np.argmax(pred) for pred in y_pred_encoded]
confusion = confusion_matrix(y_encoded_test,y_pred_labels)
accuracy = accuracy_score(y_encoded_test,y_pred_labels)*100
precision = precision_score(y_encoded_test,y_pred_labels,average='weighted')*100
f1 = f1_score(y_encoded_test,y_pred_labels,average='weighted')*100
recall = recall_score(y_encoded_test,y_pred_labels,average='weighted')*100
print(f"Confusion Matrix : \n{confusion}\n")
print(f"Accuracy : {accuracy}%\n")
print(f"Precision : {precision}%\n")
print(f"F1 : {f1}\n")
print(f"Recall : {recall}")
